# The main build pipeline

stages:
  - prep
  - build
  - deploy

# The child pipeline needs at minimum one job to run - otherwise the sub-pipeline fails
# See https://gitlab.com/gitlab-org/gitlab/-/issues/218538
dummy:
  stage: build
  variables:
    GIT_STRATEGY: none
  script:
    - ":"

# Build the docker image with all dependencies installed.
docker-build:
  stage : prep
  image: docker:$DOCKER
  needs:
   - pipeline: $PARENT_PIPELINE_ID
     job: build_vars
     artifacts: true
  rules:
   - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
     changes: ["**/*.cabal", "cabal.project"]
  script:
     - ./ci/ci-docker-build.sh $MAINVERSION hasklepias-build haskell $GHC

main-build:
  stage: build
  variables:
    HADDOCK_DIR: install
  needs:
    - pipeline: $PARENT_PIPELINE_ID
      job: build_vars
      artifacts: true
    - job: "docker-build"
      optional: true
  rules:
    - changes: ["**/*.cabal", "**/*.hs", "ci/ci-cabal-build-all.sh"]
    - if: '$CI_COMMIT_MESSAGE =~ /-build/'
  image: registry.novisci.com/nsstat/asclepias/hasklepias-build:${MAINVERSION}
  script:
     - ./ci/ci-cabal-build-all.sh
  artifacts:
    paths:
      - "$HADDOCK_DIR"
      # - coverage-report.txt
    expire_in: 1 hour

# Upload docs to S3
upload-haddock-docs:
  image: registry.novisci.com/nsstat/nsbuild/aws:latest
  needs:
    - pipeline: $PARENT_PIPELINE_ID
      job: build_vars
      artifacts: true
    - job: "main-build"
      optional: false
      artifacts: true
  rules:
    - changes: ["**/*.cabal", "**/*.hs"]
    - if: '$CI_COMMIT_MESSAGE =~ /-build/'
  stage: deploy
  script:
    - ./ci/ci-upload-docs-to-s3.sh
